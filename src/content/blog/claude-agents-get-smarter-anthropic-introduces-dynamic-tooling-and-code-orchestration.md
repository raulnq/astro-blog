---
title: "Claude Agents Get Smarter: Anthropic Introduces Dynamic Tooling and Code Orchestration"
description: "Anthropic has rolled out three beta features for Claude's developer platform, aiming to resolve significant context bloat and performance issues in LLM agent workflows. These new capabilities introduce dynamic tool discovery, code-based orchestration, and usage examples to enhance agent efficiency and accuracy."
date: 2025-12-02
tags: ["anthropic","claude","llm-agents","mcp","tooling"]
source: "https://www.youtube.com/watch?v=hPPTrsUzLA8"
---
Anthropic has launched a suite of "Advanced Tool Use" beta features for its Claude developer platform, directly addressing long-standing inefficiencies and limitations in LLM agent performance, particularly those associated with the Model Context Protocol (MCP). Industry experts have frequently criticized MCP's inherent design, which necessitates pre-loading all tool definitions into an agent's context. This approach leads to significant "context bloat," inflated token usage, slower execution, and reduced model effectiveness, likened to an LLM having to read an entire dictionary for every single lookup.

The new features—the Tool Search Tool, Programmatic Tool Calling, and Tool Use Examples—aim to mitigate these issues by making tool integration more dynamic and code-centric. The **Tool Search Tool** introduces dynamic discovery and on-demand loading of relevant tools, marked with a `defer_loading: true` flag, which can reduce token usage by up to 85% and significantly improve accuracy (e.g., Claude Opus 4 improved from 49% to 74% in internal MCP evaluations). **Programmatic Tool Calling** enables Claude to orchestrate complex workflows by generating and executing code (currently Python) for multiple tool calls, processing outputs, and controlling the information returned to the context window. This approach mitigates context pollution from intermediate results and inference overhead, yielding far greater reliability for data processing compared to natural language parsing. Lastly, **Tool Use Examples** allow developers to embed concrete usage patterns directly within tool definitions, clarifying parameter usage and API conventions beyond JSON schemas, which improved accuracy on complex parameter handling from 72% to 90%. While these advancements promise more robust and efficient agents, they are also seen by some as intricate workarounds for underlying architectural challenges within current LLM agent standards, adding considerable layers of engineering complexity to the development process.