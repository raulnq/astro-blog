---
title: "Anthropic Unveils Haiku 4.5: A Faster, Cheaper Model Reshaping AI Development"
description: "Anthropic's new Haiku 4.5 offers near-frontier coding performance at a significantly lower cost and higher speed, marking a strategic shift towards accessible, high-efficiency models. This release aims to challenge existing market leaders and empower real-time AI applications."
date: 2025-10-16
tags: ["anthropic","haiku","llm","coding ai","model release"]
source: "https://www.youtube.com/watch?v=iES9r7AZP1s"
---
Anthropic has launched Haiku 4.5, a new small model designed to deliver high intelligence with remarkable speed and cost efficiency, targeting the burgeoning need for robust, affordable AI solutions. This release marks Anthropic's first significant update to its smaller model tier since Haiku 3.5 approximately a year ago, addressing a market demand for less expensive, yet powerful, models. Haiku 4.5 is positioned as a highly capable coding model, with Anthropic claiming it offers performance levels similar to the Sonnet 4 model released five months prior, but at one-third the cost and more than twice the speed. It also reportedly competes closely with GPT-5 codecs for coding tasks and demonstrates significantly faster throughput, achieving approximately 150 tokens per second (TPS) compared to Sonnet 4.5's 45 TPS or GPT-5 codecs' 25 TPS. While its pricing sees a slight increase from Haiku 3.5 ($1 per million input tokens, $5 per million output tokens), it remains highly competitive for its performance tier.

Beyond raw performance, Haiku 4.5 signals a strategic pivot for Anthropic, moving towards more balanced, mid-tier models, possibly influenced by the competitive landscape and the perceived size of rivals like GPT-5. Industry analysis, including benchmarks from Artificial Analysis, suggests Haiku 4.5 is highly cost-effective, with benchmark runs costing around $105 (reasoning off) to $260 (reasoning on), placing it competitively with models like DeepSeek R1 and GLM 4.6. In terms of intelligence, it slightly outperforms Gemini 2.5 Flash and Qwen 3AX, though it is reported to be marginally less intelligent than GLM 4.6, indicating a direct competitive response. Notably, Haiku 4.5 is the first small Anthropic model to feature an "extended thinking mode" and supports an expanded context window of up to 200k tokens with a 64k maximum output, designed to mitigate "agentic laziness" and improve persistent reasoning. The model also boasts enhanced safety metrics, showing statistically significant improvements in alignment and lower rates of misaligned behaviors compared to Sonnet 4.5 and Opus 4.1, making it Anthropic's safest model to date by this metric. Partners like Augment Code and Warp have lauded Haiku 4.5 for its "near frontier coding quality" and instantaneous feel in AI assistant development.