---
title: "Apple Reportedly Inks $1 Billion Google Deal to Revitalize Siri with Custom Gemini Model"
description: "Facing significant AI challenges, Apple is reportedly partnering with Google for a custom 1.2 trillion-parameter Gemini-based model. This strategic move aims to overhaul Siri while addressing Apple's internal data deficit and commitment to user privacy."
date: 2025-11-06
tags: ["apple","google","ai","siri","llm"]
source: "https://www.youtube.com/watch?v=LwPNjhjf0-8"
---
Apple is reportedly committing $1 billion to Google for a custom large language model (LLM), believed to be based on Gemini 3 with 1.2 trillion parameters, aimed at powering Siri. This significant partnership comes as Apple faces scrutiny over its AI capabilities, with Siri's performance widely criticized and the anticipated 'Apple Intelligence' yet to materialize. The reported sum is notably presented as the more cost-effective option after Apple explored alternatives with other prominent AI developers. Internally, Apple's largest developed model is said to possess only 150 billion parameters, highlighting a considerable gap compared to Google's offering. A primary challenge for Apple stems from its business model, which prioritizes user privacy over extensive data collection, resulting in a 'data deficit' for LLM training—a stark contrast to data-rich competitors like Google, Microsoft, Meta, OpenAI, and Anthropic.

Google's motivation for the partnership appears strategic; by collaborating with Apple, it may deter other rivals (such as Meta, OpenAI, or Anthropic) from gaining a foothold with iPhone users. This alignment is further facilitated by Google's perceived ranking of Apple as a low-priority competitor. Concurrently, Apple is advancing its 'private cloud compute' initiatives, with recent public code updates indicating robust development to enable secure, privacy-preserving AI processing. This technology aims to allow users to leverage cloud AI without Apple accessing the message's content. The industry trend is also shifting towards training models on programmatically generated or curated data, using outputs from larger models to refine smaller, more efficient ones—a potential pathway for Apple to develop its own models in the future. Furthermore, Siri's leadership has recently transitioned to Mike Rockwell, previously instrumental in the Vision Pro project, signaling a renewed internal focus on improving the voice assistant's efficacy.